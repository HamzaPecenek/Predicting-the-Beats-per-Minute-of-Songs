{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91720,"databundleVersionId":13345277,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1) SETUP\nimport os, math, gc, warnings, json\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error, make_scorer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.linear_model import Ridge\n\nwarnings.filterwarnings(\"ignore\")\nsns.set_theme(context=\"notebook\", style=\"whitegrid\")\npd.set_option(\"display.float_format\", lambda x: f\"{x:,.6f}\")\n\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)\n\nDATA_DIR = \"/kaggle/input/playground-series-s5e9/\"\nTRAIN = os.path.join(DATA_DIR, \"train.csv\")\nTEST  = os.path.join(DATA_DIR, \"test.csv\")\nSUB_SAMP = os.path.join(DATA_DIR, \"sample_submission.csv\")\n\nTARGET = \"BeatsPerMinute\"\nID_COL = \"id\"\n\n# Optional libs\nHAS_LGB = True\ntry:\n    import lightgbm as lgb\nexcept Exception:\n    HAS_LGB = False\n    print(\"LightGBM not available; skipping that model.\")\n\ndef rmse(y_true, y_pred):\n    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n\nrmse_scorer = make_scorer(lambda yt, yp: rmse(yt, yp), greater_is_better=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T18:31:01.698280Z","iopub.execute_input":"2025-09-02T18:31:01.698588Z","iopub.status.idle":"2025-09-02T18:31:08.929535Z","shell.execute_reply.started":"2025-09-02T18:31:01.698563Z","shell.execute_reply":"2025-09-02T18:31:08.928672Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# 2) LOAD DATA & DEFINE FEATURES\ntrain = pd.read_csv(TRAIN)\ntest  = pd.read_csv(TEST)\n\nprint(\"Shapes:\", train.shape, test.shape)\nassert TARGET in train.columns and ID_COL in train.columns and ID_COL in test.columns\n\n# Numeric features only, excluding id/target\nnumeric_cols = [c for c in train.columns \n                if c not in [TARGET, ID_COL] and pd.api.types.is_numeric_dtype(train[c])]\nprint(\"Using numeric features:\", numeric_cols)\n\nX = train[numeric_cols].astype(\"float32\")\ny = train[TARGET].astype(\"float32\").values\nX_test = test[numeric_cols].astype(\"float32\")\n\nbpm_min, bpm_max = float(train[TARGET].min()), float(train[TARGET].max())\nprint(f\"BPM range (train): [{bpm_min:.3f}, {bpm_max:.3f}]\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T18:31:14.196982Z","iopub.execute_input":"2025-09-02T18:31:14.197641Z","iopub.status.idle":"2025-09-02T18:31:16.270877Z","shell.execute_reply.started":"2025-09-02T18:31:14.197612Z","shell.execute_reply":"2025-09-02T18:31:16.269701Z"}},"outputs":[{"name":"stdout","text":"Shapes: (524164, 11) (174722, 10)\nUsing numeric features: ['RhythmScore', 'AudioLoudness', 'VocalContent', 'AcousticQuality', 'InstrumentalScore', 'LivePerformanceLikelihood', 'MoodScore', 'TrackDurationMs', 'Energy']\nBPM range (train): [46.718, 206.037]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 3) CV SETUP + EVALUATOR\nCV_SPLITS = 3\ncv = KFold(n_splits=CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n\ndef evaluate(name, estimator, X, y, cv=cv, scorer=rmse_scorer):\n    scores = -cross_val_score(estimator, X, y, cv=cv, scoring=scorer, n_jobs=-1)\n    print(f\"{name:18s} RMSE (CV={cv.get_n_splits()}): {scores.mean():.4f} ± {scores.std():.4f}\")\n    return {\"model\": name, \"rmse_mean\": scores.mean(), \"rmse_std\": scores.std(), \"estimator\": estimator}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T18:31:18.101630Z","iopub.execute_input":"2025-09-02T18:31:18.101955Z","iopub.status.idle":"2025-09-02T18:31:18.107696Z","shell.execute_reply.started":"2025-09-02T18:31:18.101929Z","shell.execute_reply":"2025-09-02T18:31:18.106861Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# 3B) FAST CV SAMPLE (bounds runtime)\nFAST_CV = True\nCV_SAMPLE = 150_000   # adjust smaller if needed (e.g., 100_000)\n\nif FAST_CV and len(X) > CV_SAMPLE:\n    cv_idx = np.random.RandomState(42).choice(len(X), CV_SAMPLE, replace=False)\n    X_cv = X.iloc[cv_idx].copy()\n    y_cv = y[cv_idx].copy()\nelse:\n    X_cv = X\n    y_cv = y\n\nprint(f\"CV will use {len(X_cv):,} rows out of {len(X):,}.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T18:36:47.036495Z","iopub.execute_input":"2025-09-02T18:36:47.036797Z","iopub.status.idle":"2025-09-02T18:36:47.073886Z","shell.execute_reply.started":"2025-09-02T18:36:47.036773Z","shell.execute_reply":"2025-09-02T18:36:47.072931Z"}},"outputs":[{"name":"stdout","text":"CV will use 150,000 rows out of 524,164.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# 4) DEFINE FAST MODELS\nmodels = []\n\n# A) Dummy (mean)\nmodels.append((\"Dummy(mean)\", DummyRegressor(strategy=\"mean\")))\n\n# B) Ridge on raw features (standardized)\nmodels.append((\n    \"Ridge\",\n    Pipeline([\n        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n        (\"ridge\", Ridge(alpha=1.0, random_state=RANDOM_STATE))\n    ])\n))\n\n# C) Ridge on polynomial degree=2 (captures simple interactions; still fast here)\n#    Keep degree=2 to limit feature explosion (≈ features + squares + pairwise inter.).\nmodels.append((\n    \"Poly2+Ridge\",\n    Pipeline([\n        (\"poly\",   PolynomialFeatures(degree=2, include_bias=False)),\n        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n        (\"ridge\",  Ridge(alpha=1.0, random_state=RANDOM_STATE))\n    ])\n))\n\n# D) LightGBM (tree ensemble) — small, fast config\nif HAS_LGB:\n    lgbm = lgb.LGBMRegressor(\n        objective=\"regression\",\n        n_estimators=600,          # modest rounds\n        learning_rate=0.05,\n        num_leaves=31,\n        max_depth=-1,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        reg_alpha=0.0,\n        reg_lambda=0.0,\n        random_state=RANDOM_STATE,\n        n_jobs=-1\n    )\n    models.append((\"LightGBM\", lgbm))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T18:36:48.919757Z","iopub.execute_input":"2025-09-02T18:36:48.920075Z","iopub.status.idle":"2025-09-02T18:36:48.927820Z","shell.execute_reply.started":"2025-09-02T18:36:48.920048Z","shell.execute_reply":"2025-09-02T18:36:48.926793Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# 5) FAST CROSS-VALIDATION (RMSE) with bounded data + LGBM early stopping\ncv_results = []\n\ndef evaluate_fast(name, estimator, Xc, yc, cv=cv):\n    # Generic sklearn models via cross_val_score (on sampled rows)\n    scores = -cross_val_score(estimator, Xc, yc, cv=cv, scoring=rmse_scorer, n_jobs=-1)\n    print(f\"{name:18s} RMSE (CV={cv.get_n_splits()}): {scores.mean():.4f} ± {scores.std():.4f}\")\n    return {\"model\": name, \"rmse_mean\": scores.mean(), \"rmse_std\": scores.std(), \"estimator\": estimator}\n\n# A) Dummy\nfor name, est in models:\n    if name != \"LightGBM\":\n        res = evaluate_fast(name, est, X_cv, y_cv, cv=cv)\n        res[\"name\"] = name\n        cv_results.append(res)\n\n# B) LightGBM with early stopping (custom loop)\nif HAS_LGB and any(n == \"LightGBM\" for n, _ in models):\n    params = dict(\n        objective=\"regression\",\n        learning_rate=0.05,\n        num_leaves=31,\n        max_depth=-1,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        reg_alpha=0.0,\n        reg_lambda=0.0,\n        random_state=RANDOM_STATE,\n        n_jobs=-1\n    )\n    NUM_BOOST_ROUND = 600\n    EARLY_STOP = 100\n\n    rmses, iters = [], []\n    for fold, (tr_idx, va_idx) in enumerate(cv.split(X_cv), 1):\n        X_tr, X_va = X_cv.iloc[tr_idx].values, X_cv.iloc[va_idx].values\n        y_tr, y_va = y_cv[tr_idx], y_cv[va_idx]\n\n        model = lgb.LGBMRegressor(**params, n_estimators=NUM_BOOST_ROUND)\n        model.fit(\n            X_tr, y_tr,\n            eval_set=[(X_va, y_va)],\n            eval_metric=\"rmse\",\n            callbacks=[lgb.early_stopping(EARLY_STOP, verbose=False)],\n        )\n        pred_va = model.predict(X_va, num_iteration=model.best_iteration_)\n        fold_rmse = rmse(y_va, pred_va)\n        rmses.append(fold_rmse)\n        iters.append(model.best_iteration_)\n\n        print(f\"LightGBM (fold {fold})  RMSE={fold_rmse:.4f}  best_iter={model.best_iteration_}\")\n\n    rmse_mean, rmse_std = float(np.mean(rmses)), float(np.std(rmses))\n    best_iter_median = int(np.median(iters))\n    print(f\"LightGBM (early-stop)    RMSE (CV={cv.get_n_splits()}): {rmse_mean:.4f} ± {rmse_std:.4f} | median_iter={best_iter_median}\")\n\n    # store an unfitted template with tuned n_estimators for final training\n    tuned_lgbm = lgb.LGBMRegressor(**params, n_estimators=best_iter_median)\n    cv_results.append({\"model\":\"LightGBM(es)\", \"rmse_mean\": rmse_mean, \"rmse_std\": rmse_std, \"estimator\": tuned_lgbm, \"name\":\"LightGBM(es)\"})\n\n# Summary table\nres_df = pd.DataFrame([{k:v for k,v in r.items() if k in (\"model\",\"rmse_mean\",\"rmse_std\")} for r in cv_results]) \\\n           .sort_values(\"rmse_mean\")\ndisplay(res_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T18:36:58.680744Z","iopub.execute_input":"2025-09-02T18:36:58.681189Z","iopub.status.idle":"2025-09-02T18:37:04.513967Z","shell.execute_reply.started":"2025-09-02T18:36:58.681163Z","shell.execute_reply":"2025-09-02T18:37:04.513138Z"}},"outputs":[{"name":"stdout","text":"Dummy(mean)        RMSE (CV=3): 26.4449 ± 0.0371\nRidge              RMSE (CV=3): 26.4454 ± 0.0370\nPoly2+Ridge        RMSE (CV=3): 26.4494 ± 0.0344\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005449 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2295\n[LightGBM] [Info] Number of data points in the train set: 100000, number of used features: 9\n[LightGBM] [Info] Start training from score 118.980957\nLightGBM (fold 1)  RMSE=26.4644  best_iter=23\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005608 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2295\n[LightGBM] [Info] Number of data points in the train set: 100000, number of used features: 9\n[LightGBM] [Info] Start training from score 118.966757\nLightGBM (fold 2)  RMSE=26.3915  best_iter=63\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005841 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2295\n[LightGBM] [Info] Number of data points in the train set: 100000, number of used features: 9\n[LightGBM] [Info] Start training from score 118.954929\nLightGBM (fold 3)  RMSE=26.4719  best_iter=11\nLightGBM (early-stop)    RMSE (CV=3): 26.4426 ± 0.0362 | median_iter=23\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"          model  rmse_mean  rmse_std\n3  LightGBM(es)  26.442589  0.036223\n0   Dummy(mean)  26.444877  0.037093\n1         Ridge  26.445400  0.036989\n2   Poly2+Ridge  26.449394  0.034380","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>rmse_mean</th>\n      <th>rmse_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>LightGBM(es)</td>\n      <td>26.442589</td>\n      <td>0.036223</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Dummy(mean)</td>\n      <td>26.444877</td>\n      <td>0.037093</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ridge</td>\n      <td>26.445400</td>\n      <td>0.036989</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Poly2+Ridge</td>\n      <td>26.449394</td>\n      <td>0.034380</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# 6) PICK BEST MODEL & FIT ON FULL TRAIN\nbest = min(cv_results, key=lambda d: d[\"rmse_mean\"])\nbest_name = best[\"name\"]\nbest_est  = best[\"estimator\"]\n\nprint(f\"Best model by CV: {best_name}\")\nbest_est.fit(X, y)\n\n# Keep reference to fitted pipeline/estimator for later\nfitted = best_est\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T18:37:13.806536Z","iopub.execute_input":"2025-09-02T18:37:13.806865Z","iopub.status.idle":"2025-09-02T18:37:14.840517Z","shell.execute_reply.started":"2025-09-02T18:37:13.806840Z","shell.execute_reply":"2025-09-02T18:37:14.839757Z"}},"outputs":[{"name":"stdout","text":"Best model by CV: LightGBM(es)\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055696 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2295\n[LightGBM] [Info] Number of data points in the train set: 524164, number of used features: 9\n[LightGBM] [Info] Start training from score 119.034899\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# 7) PREDICT TEST & POSTPROCESS\npred = fitted.predict(X_test).astype(\"float32\")\n\n# Clip to train range (avoids crazy tails if any)\npred = np.clip(pred, bpm_min, bpm_max)\n\nsubmit = pd.DataFrame({\n    ID_COL: test[ID_COL].values,\n    TARGET: pred\n})\ndisplay(submit.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T18:37:17.725685Z","iopub.execute_input":"2025-09-02T18:37:17.725990Z","iopub.status.idle":"2025-09-02T18:37:17.825937Z","shell.execute_reply.started":"2025-09-02T18:37:17.725969Z","shell.execute_reply":"2025-09-02T18:37:17.824598Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"       id  BeatsPerMinute\n0  524164      119.172691\n1  524165      118.966782\n2  524166      119.316147\n3  524167      119.220230\n4  524168      119.300903","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>BeatsPerMinute</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>524164</td>\n      <td>119.172691</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>524165</td>\n      <td>118.966782</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>524166</td>\n      <td>119.316147</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>524167</td>\n      <td>119.220230</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>524168</td>\n      <td>119.300903</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# 8) SAVE SUBMISSION\nOUT_PATH = \"/kaggle/working/submit.csv\"\nsubmit.to_csv(OUT_PATH, index=False)\nprint(f\"Saved: {OUT_PATH}\")\n\n# Also save CV summary + chosen model meta\nmeta = {\n    \"cv_results\": res_df.to_dict(orient=\"list\"),\n    \"best_model\": best_name,\n    \"random_state\": RANDOM_STATE,\n    \"features\": numeric_cols,\n    \"bpm_minmax\": [bpm_min, bpm_max]\n}\nPath(\"/kaggle/working/baseline_meta.json\").write_text(json.dumps(meta, indent=2))\nprint(\"Saved: /kaggle/working/baseline_meta.json\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T18:37:31.355721Z","iopub.execute_input":"2025-09-02T18:37:31.356096Z","iopub.status.idle":"2025-09-02T18:37:31.654255Z","shell.execute_reply.started":"2025-09-02T18:37:31.356061Z","shell.execute_reply":"2025-09-02T18:37:31.653062Z"}},"outputs":[{"name":"stdout","text":"Saved: /kaggle/working/submit.csv\nSaved: /kaggle/working/baseline_meta.json\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}